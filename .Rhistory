odds<-exp(a+b*x)/(1+exp(a+b*x));
log(odds/(1-odds))
}
curve(log_odds, from = -60, to = 60, col = 2)
par(mfrow=c(1,2))
odds<-function(x, a=1, b=0.1){exp(a+b*x)/(1+exp(a+b*x))}
curve(odds, from = -60, to = 60, col = 2)
log_odds<-function(x, a=1, b=0.1){
odds<-exp(a+b*x)/(1+exp(a+b*x));
log(odds/(1-odds))
}
curve(log_odds, from = -60, to = 60, col = 2)
make.power(2)
num1 <- function(x) { # outer function
num2 <- function(y) { # inner function
return(x*y)
}
return(num2)
}
make.power(2)
num1 <- function(x) { # outer function
num2 <- function(y) { # inner function
return(x*y)
}
return(num2)
}
result <- num1(10)
print(result)
result
result <- num1(10)
result
num1 <- function(x) { # outer function
num2 <- function(y) { # inner function
return(x*y)
}
return(num2)
}
num1(10)
par(mfrow=c(1,2))
p<-function(x, a=1, b=0.1){exp(a+b*x)/(1+exp(a+b*x))}
curve(p, from = -60, to = 60, col = 2)
log_p<-function(x, a=1, b=0.1){
p<-exp(a+b*x)/(1+exp(a+b*x));
log(p/(1-p))
}
curve(log_p, from = -60, to = 60, col = 2)
p<-function(x, a=1, b=0.1){exp(a+b*x)/(1+exp(a+b*x))}
log_p<-function(x, a=1, b=0.1){
log(p/(1-p))
}
curve(log_p, from = -60, to = 60, col = 2)
par(mfrow=c(1,2))
p<-function(x, a=1, b=0.1){exp(a+b*x)/(1+exp(a+b*x))}
curve(p, from = -60, to = 60, col = 2)
log_p<-function(x, a=1, b=0.1){
p<-exp(a+b*x)/(1+exp(a+b*x));
log(p/(1-p))
}
curve(log_p, from = -60, to = 60, col = 2)
log_p<-function(x, a=1, b=0.1){
log(p(x)/(1-p(x)))
}
curve(log_p, from = -60, to = 60, col = 2)
par(mfrow=c(1,2))
p<-function(x, a=1, b=0.1){exp(a+b*x)/(1+exp(a+b*x))}
curve(p, from = -60, to = 60, col = 2)
log_p<-function(x, a=1, b=0.1){
log(p(x)/(1-p(x)))
}
curve(log_p, from = -60, to = 60, col = 2)
library(tidyverse)  # data manipulation and visualization
library(modelr)     # provides easy pipeline modeling functions
library(broom)
library(ISLR)
(default <- as_tibble(ISLR::Default))
#prepare data
set.seed(123)
sample <- sample(c(TRUE, FALSE), nrow(default), replace = T, prob = c(0.6,0.4))
train <- default[sample, ]
test <- default[!sample, ]
model1 <- glm(default ~ balance, family = "binomial", data = train)
default %>%
mutate(prob = ifelse(default == "Yes", 1, 0)) %>%
ggplot(aes(balance, prob)) +
geom_point(alpha = .15) +
geom_smooth(method = "glm", method.args = list(family = "binomial")) +
ggtitle("Logistic regression model fit") +
xlab("Balance") +
ylab("Probability of Default")
summary(model1)
tidy(model1)
exp(coef(model1))
confint(model1)
predict(model1, data.frame(balance = c(1000, 2000)), type = "response")
model2 <- glm(default ~ student, family = "binomial", data = train)
tidy(model2)
predict(model2, data.frame(student = factor(c("Yes", "No"))), type = "response")
model3 <- glm(default ~ balance + income + student, family = "binomial", data = train)
tidy(model3)
head(default)
data(iris)
x <- iris[sample(1:nrow(iris)),]
x <- cbind(x, useless = rnorm(nrow(x)))
head(x)
x$virginica <- x$Species == "virginica"
x$Species <- NULL
plot(x, col=x$virginica+1)
names(x)
head(x)
model <- glm(virginica ~ .,
family = binomial(logit), data=x)
model
summary(model)
model
summary(model)
?glm
head(x)
?step
?AIC
model2<-step(model,data=x)
names(model2)
summary(model2)
#step 1
data(iris)
x <- iris[sample(1:nrow(iris)),]
x <- cbind(x, useless = rnorm(nrow(x)))
x$virginica <- x$Species == "virginica"
x$Species <- NULL
plot(x, col=x$virginica+1)
head(x)
#step 1
data(iris)
x<-iris
x <- cbind(x, useless = rnorm(nrow(x)))
x$virginica <- x$Species == "virginica"
x$Species <- NULL
head(x)
tail(x)
iris
nrow(iris)
sd(iris)
head(iris)
sd(iris[,1:4])
iris[,1:4]
sd(iris[,1:4])
sapply(iris[,1:4], sd)
model<-prcomp(iris[,1:4],scale=TRUE)
summary(model)
names(model)
model$sdev
model$scale
model$x
summary(model)
plot(model,main"",col="olive")
plot(model,main="",col="olive")
plot(model,main="",col="red")
biplot(model,main="",col="red")
plot(iris$Sepal.Length,yv,pch=16)
yv<-predict(model)[,1]
yv2<-predict(model)[,2]
par(mfrow=c(1,2))
plot(iris$Sepal.Length,yv,pch=16)
nrow(iris)
head(iris)
model<-prcomp(iris[,1:4],scale=TRUE)
summary(model)
plot(model,main="",col="red")
biplot(model,main="",col="red")
yv<-predict(model)[,1]
yv2<-predict(model)[,2]
par(mfrow=c(1,2))
plot(iris$Sepal.Length,yv,pch=16)
plot(iris$Sepal.Length,yv2,pch=16)
screeplot(model)
plot(model,main="",col="red")
yv<-predict(model)[,1]
yv2<-predict(model)[,2]
par(mfrow=c(1,2))
plot(iris$Sepal.Width,yv,pch=16)
plot(iris$Sepal.Width,yv2,pch=16)
yv<-predict(model)[,1]
yv2<-predict(model)[,2]
par(mfrow=c(4,2))
plot(iris$Sepal.Width,yv,pch=16)
plot(iris$Sepal.Width,yv2,pch=16)
plot(iris$Sepal.Length,yv,pch=16)
plot(iris$Sepal.Length,yv2,pch=16)
plot(iris$Petal.Width,yv,pch=16)
plot(iris$Petal.Width,yv2,pch=16)
plot(iris$Petal.Length,yv,pch=16)
plot(iris$Petal.Length,yv2,pch=16)
summary(model)
biplot(model,main="",col="red")
dev.off()
plot(model,main="",col="red")
biplot(model,main="",col="red")
PC1<-predict(model)[,1]
PC2<-predict(model)[,2]
par(mfrow=c(2,2))
plot(iris$Sepal.Width,PC1,pch=16)
plot(iris$Sepal.Length,PC1,pch=16)
plot(iris$Petal.Width,PC1,pch=16)
plot(iris$Petal.Length,PC1,pch=16)
nrow(iris)
head(iris)
model<-prcomp(iris[,-5],center=TRUE,scale=TRUE) # scale TRUE to compensate for different variances
model
names(model)
model$rotation
model
summary(model)
model
biplot(model,main="",col="red")
biplot(model,main="",col="red", ellipse=TRUE)
dev.off()
biplot(model,main="",col="red", ellipse=TRUE)
pairs(iris[,-5])
?pairs
panel.cor[,-5])
panel.cor <- function(x, y, ...)
{
par(usr = c(0, 1, 0, 1))
txt <- as.character(format(cor(x, y), digits=2))
text(0.5, 0.5, txt, cex = 6* abs(cor(x, y)))
}
pairs(iris[1:4], upper.panel=panel.cor)
library(PerformanceAnalytics)
library(PerformanceAnalytics)
chart.Correlation(iris[,-5],method="pearson")
model$x
chart.Correlation(model$x,method="pearson")
model
head(model$x)
model
model$rotation[1,]
model$rotation[1,]*iris[1,-5]
model$x[1,]
model$rotation[,1]*iris[1,-5]
model$x[1,]
iris[1,-5]*model$rotation[,1]
model$x[1,]
model
model$x[1,]
model$rotation[,1]
model$rotation[,1]
iris[1,-5]
dim(model$rotation[,1])
model$rotation[,1]
iris[1,-5]
biplot(model,main="",col="red", ellipse=TRUE)
pred<-predict(model,iris[1:5,-5])
pred
model$x[1:5,]
setwd("~/Documents/Dropbox/concursR/EstadÃ­stica_amb_R")
name<-c("Paul","John","Melinda")
age<-c(24,22,27)
threecol<-rbind(name,age)
threecol
twocol<-cbind(name,age)
twocol
nameAge<-data.frame(name,age)
nameAge
heightWeight<-data.frame(height=c(170,167,177),weight=c(70,67,77))
cbind(nameAge,heightWeight)
nameAge
heightWeight<-data.frame(name=c("Paul","John","Melinda","Tim"),
height=c(160,167,177,168),
weight=c(70,67,82,68))
heightWeight
merge(nameAge,heightWeight,by="name")
name<-c("Paul","John","Melinda")
age<-c(24,22,27)
print(threecol)
names <- c("Paul","John","Melinda")
ages <- c(24,22,27)
threecol<-rbind(names,ages)
print(threecol)
namesAges<-data.frame(names,ages)
namesAges
heightsWeights<-data.frame(heights=c(170,167,177),weights=c(70,67,77))
cbind(namesAges,heightsWeights)
names <- c("Paul","John","Melinda")
ages <- c(24,22,27)
namesAges<-data.frame(names,ages)
namesAges
heightsWeights<-data.frame(heights=c(170,167,177),
weights=c(70,67,77))
cbind(namesAges,heightsWeights)
namesAges
heightsWeights2<-data.frame(names=c("Paul","John","Melinda","Tim"),
heights=c(160,167,177,168),
weights=c(70,67,82,68))
heightsWeights2
merge(namesAges,heightsWeights2,by="names")
merge(namesAges,heightsWeights2,by="names",all=FALSE) #inner join
merge(namesAges,heightsWeights2,by="names",all=TRUE) #outer join
merge(namesAges,heightsWeights2,by="names",all.x=TRUE) #left join
merge(namesAges,heightsWeights2,by="names",all.y=TRUE) #right join
merge(namesAges,heightsWeights2,by=NULL) #cross join
mydf<-merge(namesAges,heightsWeights2,by="name",all=FALSE)
mydf<-merge(namesAges,heightsWeights2,by="names",all=FALSE)
mydf<-merge(namesAges,heightsWeights2,by="names",all=FALSE)
bmi<-mydf$weights/(mydf$heights/100)^2
mydf<-cbind(mydf,bmi)
mydf
avg<-colMeans(mydf[,2:5])
round(avg,2) #round at 2 decimals
avg<-colMeans(mydf[,2:5])
newAvg<-mydf[1,]
newAvg[1]<-"AVERAGE"
newAvg[2:5]<-round(avg,2)
newAvg
rbind(mydf,newAvg)
bmi<-round(mydf$weights/(mydf$heights/100)^2),2)
bmi<-round(mydf$weights/(mydf$heights/100)^2),2)
bmi<-round(mydf$weights/(mydf$heights/100)^2,2)
mydf<-cbind(mydf,bmi)
mydf
mydf<-merge(namesAges,heightsWeights2,by="names",all=FALSE)
bmi<-round(mydf$weights/(mydf$heights/100)^2,2)
mydf<-cbind(mydf,bmi)
mydf
mydf<-merge(namesAges,heightsWeights2,by="names",all=FALSE)
bmi<-round(mydf$weights/(mydf$heights/100)^2,0)
mydf<-cbind(mydf,bmi)
mydf
avg<-colMeans(mydf[,2:5])
round(avg,2) #round at 2 decimals
avg<-colMeans(mydf[,2:5])
newAvg<-mydf[1,]
newAvg[1]<-"AVERAGE"
newAvg[2:5]<-round(avg,2)
newAvg
rbind(mydf,newAvg)
namesAges
mydf<-merge(namesAges,heightsWeights2,by="name",all=FALSE)
heightsWeights2<-data.frame(names=c("Paul","John","Melinda","Tim"),
heights=c(160,167,177,168),
weights=c(70,67,102,68))
heightsWeights2
merge(namesAges,heightsWeights2,by="names")
mydf<-merge(namesAges,heightsWeights2,by="names",all=FALSE)
bmi<-round(mydf$weights/(mydf$heights/100)^2,0)
mydf<-cbind(mydf,bmi)
mydf
mydf
overweight <- mydf$bmi>=30,TRUE,FALSE
overweight <- if(mydf$bmi>=30,TRUE,FALSE)
overweight <- mydf$bmi>=30
overweight
cbind(mydf,overweight)
length(mydf$names)
mydf$names
mean(mydf$weights)
overweight <- mydf$weights>=(mean(mydf$weights))
cbind(mydf,overweight)
overweight <- mydf$bmi>=30
cbind(mydf,overweight)
overweight <- (mydf$weights>=mean(mydf$weights))&
(mydf$heights<mean(mydf$heights))
cbind(mydf,overweight)
overweight <- mydf$weights>=mean(mydf$weights)&
(mydf$heights<mean(mydf$heights))
cbind(mydf,overweight)
myCars
car <-c("Ford",4,"red",FALSE,"as new",NA)
myCars <-data.frame(
atributte = c("Name","cilynders","colour",
"sport car", "observation",
"price"),
car=c("Ford",4,"red",FALSE,"as new", NA)
)
myCars
myCars
myCars<-na.omit(myCars)
myCars
absenteeism<-openintro::absenteeism #create data frame
class(absenteeism)
head(absenteeism) #head() prints a few lines
names(absenteeism) #to see col names
table(absenteeism$sex) #to count occurrences of each sex
table(absenteeism$lrn) #to count ocurrences of each learner status
table(absenteeism$sex, absenteeism$lrn)
To count the elements of each type in a vector of the data frame we will use the function \emph{table()}\index{function!table()}.
<<>>=
names(absenteeism) #to see col names
table(absenteeism$sex) #to count occurrences of each sex
table(absenteeism$lrn) #to count ocurrences of each learner status
@
If we count for more than a variable we will create a contingency table\index{contingency table}:
<<>>=
table(absenteeism$sex, absenteeism$lrn)
@
We can turn frequency tables into proportions with \emph{prop.table()}
<<>>=
mytable<-table(absenteeism$sex, absenteeism$lrn)
prop.table(mytable)
@
We can add marginals sums to frequency tables with \emph{addmargins()}
<<>>=
mytable<-table(absenteeism$sex, absenteeism$lrn)
addmargins(mytable)
@
At section \ref{Contingency Tables} we cover how to use contingency tables as an statistical test for categorical variables.
\end{subsection}
mytable<-table(absenteeism$sex, absenteeism$lrn)
prop.table(mytable)
mytable<-table(absenteeism$sex, absenteeism$lrn)
addmargins(mytable)
round(mytable*100,2)
mytable<-table(absenteeism$sex, absenteeism$lrn)
mytable<-prop.table(mytable)
round(mytable*100,2)
round(mytable*100,1)
tapply(days,list(sex),mean)
attach(absenteeism)
mean(days) #instead of mean(absenteeism$days)
sum(days)
tapply(days,list(sex),mean)
round(tapply(days,list(sex),mean),1) #rounded to 1 decimal
tapply(days,list(sex),mean)
tapply(days,list(sex,eth),sum)
meanDaysbySex<-tapply(days,list(sex),mean)
write.csv(meanDaysbySex,file="daysbySex.csv")
mydf
tapply(mydf[,2:5],sum)
tapply(days,list(sex,eth),sum)
round(mytable*100,2)
ncol(mydf)
nrow(mydf)
qchisq(0.95,1)
1-pchisq(4.096,1)
chisq.test(c(109,141),p=c(0.5,0.5))
summary(chisq.test(c(109,141),p=c(0.5,0.5)))
chisq.test(c(109,141),p=c(0.5,0.5))
chisq.test(c(44,56),p=c(0.5,0.5))
t.test(absenteeism$days)
t.test(absenteeism$days)
n.test(absenteeism$days)
s<-(aov(days~eth))
summary(s)
fit = lm(dist ~ speed, data = cars)
b   = coef(fit)
fit
head(iris)
pairs(iris[,-5])
head(iris)
model<-prcomp(iris[,-5],center=TRUE,scale=TRUE)
model
summary(model)
summary(kmModel)
kmModel<-kmeans(iris[,-5],2)
summary(kmModel)
kmModel
setwd("~/Documents/Dropbox/concursR/EstadÃ­stica_amb_R")
setwd("~/Documents/Dropbox/concursR")
library(swirlify)
new_lesson("Cluster Analysis","Statistical Anslysis with R")
getwd()
set_lesson("Cluster Analysis", "Statistical_Analysis_with_R")
swirlify()
set_lesson("Cluster Analysis", "Statistical_Analysis_with_R")
set_lesson("Cluster Analysis", "Statistical_Analysis_with_R")
new_lesson("Cluster Analysis", "Statistical_Analysis_with_R")
# Code placed in this file fill be executed every time the
# lesson is started. Any variables created here will show up in
# the user's working directory and thus be accessible to them
# throughout the lesson.
iris<-datasets::iris
set.seed(3123) #to obtain the same random sample
data<-iris[sample(nrow(iris),20),] #random sample
datasets::iris
get_current_lesson()
test_lesson()
test_lesson()
demo_lesson()
add_to_manifest()
demo_lesson()
kmModel<-kmeans(iris[,-5],2)
kmModel
iriskm<-cbind(iris,cluster=kmModel$cluster)
head(iriskm)
table(iriskm[,5:6])
irish <- hclust(dist(data[,1:4]))
plot(irish,main= "", labels=data[,5])
getwd()
install_course_github()?
swirl()
library(swirl)
swirl()
swirl()
summary(iris)
View(iris)
install_course_github()
install_course_github()
get_current_lesson()
bye
swirlify()
add_license()?
add_license?
add_license(Ramon Prat, year=format(Sys.Date),"%Y"),open_source_content= TRUE, content_license="CC BY-SA 3.0")
add_license(autor="Ramon Prat", year=format(Sys.Date),"%Y"),open_source_content= TRUE, content_license="CC BY-SA 3.0")
add_license(autor="Ramon Prat", year=format(Sys.Date),"%Y"), open_source_content= TRUE, content_license="CC BY-SA 3.0")
add_license(autor="Ramon Prat", year=format(Sys.Date),"%Y"), content_license="CC BY-SA 3.0")
add_license(autor="Ramon Prat", year=format(Sys.Date),"%Y")Y-SA 3.0")
add_license(autor="Ramon Prat", year=format(Sys.Date(),"%Y"), open_source_content= TRUE, content_license="CC BY-SA 3.0")
add_license(Ramon Prat, year=format(Sys.Date(),"%Y"), open_source_content= TRUE, content_license="CC BY-SA 3.0")
add_license("Ramon Prat", year=format(Sys.Date(),"%Y"), open_source_content= TRUE, content_license="CC BY-SA 3.0")
add_license("Ramon Prat", year=format(Sys.Date(),"%Y"), open_source_content= TRUE, content_license="CC BY-SA 4.0")
add_license("Ramon Prat", year=format(Sys.Date(),"%Y"), open_source_content= TRUE, content_license="CC BY-SA 4.0")
getwd()
setwd("~/Documents/Dropbox/concursR/Statistical_Analysis_with_R")
